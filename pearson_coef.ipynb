{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_of_original_features :  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gachon\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:3399: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_of_pearson_features :  20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "import csv\n",
    "\n",
    "\n",
    "def pearson_coef(feature, label):\n",
    "    # correlation_coefficient[0] = correlation\n",
    "    # correlation_coefficient[1] = p-value\n",
    "    correlation_coefficient = stats.pearsonr(feature, label)\n",
    "\n",
    "    coef = correlation_coefficient[0]\n",
    "\n",
    "    if math.isnan(coef):\n",
    "        return 0\n",
    "\n",
    "    return abs(coef)\n",
    "\n",
    "\n",
    "file_path = 'F:\\\\LungSound\\\\LungSound_features\\\\'\n",
    "file_name = 'img_features_93.0.csv'\n",
    "img_path = file_path + file_name\n",
    "\n",
    "dataset = np.genfromtxt(img_path, delimiter=',', encoding='UTF8')\n",
    "dataset = dataset[1:]\n",
    "print('len_of_original_features : ', len(dataset[0]) - 1)\n",
    "\n",
    "set_1 = []\n",
    "set_2 = []\n",
    "for data in dataset:\n",
    "  if data[-1] == 0:\n",
    "    set_1.append(data)\n",
    "  else:\n",
    "    set_2.append(data)\n",
    "\n",
    "set_1 = np.array(set_1)\n",
    "set_2 = np.array(set_2)\n",
    "\n",
    "dataset = np.array(dataset)\n",
    "\n",
    "scores = []\n",
    "for index in range(len(dataset[0]) - 1):\n",
    "  score = pearson_coef(dataset[:, index], dataset[:, -1])\n",
    "  temp = [score, index]\n",
    "  scores.append(temp)\n",
    "\n",
    "sorted_list = sorted(scores, key=lambda x: x[0], reverse=True)\n",
    "sorted_list = np.array(sorted_list)\n",
    "bhattacharyya_rank_index = sorted_list[:, 1]\n",
    "\n",
    "feature_name = np.genfromtxt(img_path, delimiter=',', encoding='UTF8', dtype=str)\n",
    "feature_name = feature_name[0]\n",
    "\n",
    "original_dataset = np.genfromtxt(img_path, delimiter=',', encoding='UTF8', skip_header=1)\n",
    "labels = original_dataset[:, -1]\n",
    "labels = np.expand_dims(labels, axis=1)\n",
    "dataset = original_dataset[:, :-1]\n",
    "dataset = np.transpose(dataset)\n",
    "feature_name = np.transpose(feature_name)\n",
    "\n",
    "subset = []\n",
    "f_name = []\n",
    "for index in bhattacharyya_rank_index[:20]:\n",
    "  subset.append(dataset[int(index)])\n",
    "  f_name.append(feature_name[int(index)])\n",
    "\n",
    "f_name.append('AA')\n",
    "print('len_of_pearson_features : ', len(subset))\n",
    "\n",
    "subset = np.transpose(subset)\n",
    "f_name = np.transpose(f_name)\n",
    "f_name = np.expand_dims(f_name, axis=0)\n",
    "\n",
    "dataset = np.concatenate((subset, labels), axis=1)\n",
    "bhattacharyya_dataset = np.concatenate((f_name, dataset), axis=0)\n",
    "\n",
    "f = open('pearson_' + str(len(subset[0])) + '_' + file_name, 'w', encoding='utf-8', newline='')\n",
    "wr = csv.writer(f)\n",
    "for line in bhattacharyya_dataset:\n",
    "  wr.writerow(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
